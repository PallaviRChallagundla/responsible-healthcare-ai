{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias Audit Starter Notebook\n",
    "\n",
    "This notebook provides a basic structure for evaluating demographic bias in healthcare LLM outputs.\n",
    "It simulates a simple test using synthetic prompts representing different demographic groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "groups = [\"young adult\", \"middle aged\", \"elderly\", \"male\", \"female\", \"Black\", \"White\", \"Asian\", \"Hispanic\"]\n",
    "\n",
    "# synthetic LLM risk scores\n",
    "scores = [random.uniform(0.2, 0.8) for _ in groups]\n",
    "\n",
    "df = pd.DataFrame({\"group\": groups, \"risk_score\": scores})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Bias Check\n",
    "- Compute range\n",
    "- Identify groups with unusually high/low risk scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
